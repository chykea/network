### http 1.0
> 支持:POST/GET/HEAD 方法<br>
> 无状态：服务器不跟踪不记录请求过的状态<br>
> 无连接（短连接）：浏览器每次请求都需要建立tcp连接<br>
>
> - HTTP/1.0规定浏览器和服务器保持短暂的连接。浏览器的每次请求都需要与服务器建立一个TCP连接，服务器处理完成后立即断开TCP连接（无连接），服务器不跟踪每个客户端也不记录过去的请求（无状态）
> 可以借助cookie/session机制来做身份认证和记录状态
> 但是无连接特性会导致以下性能问题：<br>
> 1. 无法复用连接。每次请求的时候都需要进行一次tcp连接(三握四挥),导致网络的利用率很低<br>
> 注：http1.0也可以开启长连接，通过在请求头Connection:Keep-alive启用长连接请求，但这个并不是1.0的标准字段
> 2. 队头阻塞。由于http1.0规定下一次请求必须在前一次请求得到响应之后才能进行，如果前一次请求一直没有响应，就会一直阻塞后面的请求

为了解决http1.0所遗留的问题。推出了http1.1
### http1.1
> 相比于1.0，1.1新增了OPTIONS/PUT/PATCH/DELETE/TRACE/CONNECT方法
> - HTTP1.1现在已经支持长连接了，新增了一个Connection字段用于开启长连接，通过`keep-alive:true`开启（默认就是开启的），如果需要关闭长连接，可以在请求头添加`Connection:false`关闭
> - 支持请求并行化（大多情况下没啥吊用）。即把客户端的请求队列的模式（请求是先进先出的）前移到服务端， 即响应也是先进先出的，比如客户端发送了两个请求html和css，
即使服务端先加载完css资源，也得等html资源处理完响应会客户端后才会发送css给客户端。
> 值得一提的是，可以在谷歌浏览器中的控制台看到并行请求，这其实是开启了多个TCP连接进行数据传输，这种方式与http1.1的请求并行化相比，前者才算是真正的并行
> - http1.1新增了缓存字段，比如强协商的Cache-control、以及协商缓存的ETag。用于优化http1.0的强协商缓存Expires的问题，以及协商缓存Last_Modified，即如果同时设置了两个缓存字段，会默认使用http1.1的缓存字段，无视http1.0的字段。

注：队头阻塞分HTTP1.1队头阻塞和TCP队头阻塞

这里所讲的是HTTP1.1的队头阻塞
为啥会发生HTTP阻塞？主要就是HTTP请求并行化，虽然客户端可以同时发送多个请求，但是服务端也是需要按照请求的顺序进行资源加载并返回响应，如果一个响应丢失或延迟了，其后序的响应都会被阻塞。

那么如何解决呢？
> - http2.0
> - 并发TCP连接（一个域名可以建立6-8TCP连接，其实上文中有提及到）
> - 域名分片（多个域名可以创建多个TCP连接，比如cdn）

### http2.0
> 首先需要了解http1.1的报文格式，http1.1报文的格式（头部与消息主体）是文本，这里要提出一个注意点：<b>TCP协议是可靠传输，面向字节流，是可以通过表示来实现多个片段合并出完整的消息</b>，<br>而http1.1的数据格式是文本格式，所以在传输过程中，如果数据流是无序的，并不能通过一个关联id把这些数据流给关联起来，因为很难给这些数据流添加关联id<br>
> http2.0实现二进制分帧层，即定义一种新的消息格式：流，每个消息包含首部帧，这个首部帧包含两个信息，一：流id，表示这个消息属于哪个资源；二：该消息消息的大小，所以不同流的信息可以交替甚至无序发送，最后根据首部帧的流id进行关联合并即可<br>
> 二进制分帧层：帧是通信中最小的单元信息<br>
> http2.0中，将请求和响应数据分割为更小的帧，并且对这些帧采用二进制编码，
每个数据流都以消息的形式发送，消息由一个帧或多个帧组成，多个帧之间可以乱序发送，根据帧首部的流标识进行组装，所以http2.0解决了http1.1的队头阻塞的问题<br>
> 首部压缩：http1.x的头带有大量信息，而且每次都要重复发送。http/2使用encoder来减少需要传输的header大小，通讯双方各自缓存一份头部字段表，既避免了重复header的传输，又减小了需要传输的大小。<br>
对于相同的数据，不再通过每次请求和响应发送，通信期间几乎不会改变通用键-值对(用户代理、可接受的媒体类型，等等)只需发送一次。<br>
事实上,如果请求中不包含首部(例如对同一资源的轮询请求)，那么，首部开销就是零字节，此时所有首部都自动使用之前请求发送的首部。<br>
如果首部发生了变化，则只需将变化的部分加入到header帧中，改变的部分会加入到头部字段表中，首部表在 http 2.0 的连接存续期内始终存在，由客户端和服务器共同渐进地更新。
<br>
> 服务端推流：比如客户端请求html文件，而在html中引用了某个css文件，服务端通过对客户端这个请求的分析得出还需要请求css文件，在响应html的过程中，也会发送对应的css文件，这样客户端就不用再发起另一个css的请求了，这个就是服务端推流

以上是HTTP1.0 HTTP1.1 HTTP2.0 的一些基本问题。接下来讲讲另一个队头阻塞，TCP队头阻塞。<br>

如上文所说，HTTP2.0是在应用层给报文添加上一个帧来进行资源的关联，但TCP不知道，甚至TCP并不知道自己在传输HTTP，TCP所知道的是它接收了一系列字节，必须从一台计算机传输到另一台计算机。为此，它使用特定最大大小的数据包，通常大约1460个字节。每个数据包只跟踪它携带的数据的那一部分（字节范围，相当于片偏移），这样原始数据就可以按照正确的顺序重建。<br>

假设现在有三个包，数据包1，数据包2和数据包3，它们通过计算偏移量后添加在TCP报文头部，然后进行按序发送，在传输过程中，1和3到达了，而2在传输过程中丢失了，由于TCP是可靠传输的，发送方知道2在传输过程中丢失后，就会进行超时重传，而接收方也知道现在只接收到1和3，并且根据发送顺序知道1现在是可用的，<b>但由于2丢失了，TCP就会把3放到缓存区中，等到再次接收到2后。才会把3向上传递。</b>这部分换句话来讲就是：<b>数据包2阻塞了数据包3，</b>如果数据包3后面还有数据包4..5...
会由于2的丢失而被放到缓冲区，阻塞了后面数据包的向上传递。


不过别担心，其实数据包丢失还是比较少见的。





